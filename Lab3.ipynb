{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d0550c7",
   "metadata": {},
   "source": [
    "# ID3 Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdf1bd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "df_tennis = pd.read_csv('lab3_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "867375af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['day', 'outlook', 'temperature', 'humidity', 'wind']\n"
     ]
    }
   ],
   "source": [
    "attribute_names = list(df_tennis.columns)\n",
    "attribute_names.remove('playtennis')\n",
    "label=\"playtennis\"\n",
    "print(attribute_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e58e94c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_total_entropy(train_data, label, class_list):\n",
    "    total_row = train_data.shape[0] \n",
    "    total_entr = 0\n",
    "    \n",
    "    for c in class_list: \n",
    "        total_class_count = train_data[train_data[label] == c].shape[0] \n",
    "        total_class_entr = - (total_class_count/total_row)*np.log2(total_class_count/total_row) \n",
    "        total_entr += total_class_entr \n",
    "    \n",
    "    return total_entr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f540f98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_entropy(feature_value_data, label, class_list):\n",
    "    class_count = feature_value_data.shape[0]\n",
    "    entropy = 0\n",
    "    \n",
    "    for c in class_list:\n",
    "        label_class_count = feature_value_data[feature_value_data[label] == c].shape[0]  \n",
    "        entropy_class = 0\n",
    "        if label_class_count != 0:\n",
    "            probability_class = label_class_count/class_count \n",
    "            entropy_class = - probability_class * np.log2(probability_class)  \n",
    "        entropy += entropy_class\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2055ea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_info_gain(train_data,feature_name, label, class_list):\n",
    "    feature_value_list = train_data[feature_name].unique() \n",
    "    total_row = train_data.shape[0]\n",
    "    feature_info = 0.0\n",
    "    \n",
    "    for feature_value in feature_value_list:\n",
    "        feature_value_data = train_data[train_data[feature_name] == feature_value] \n",
    "        feature_value_count = feature_value_data.shape[0]\n",
    "        feature_value_entropy = calc_entropy(feature_value_data, label, class_list)\n",
    "        feature_value_probability = feature_value_count/total_row\n",
    "        feature_info += feature_value_probability * feature_value_entropy \n",
    "        \n",
    "    return calc_total_entropy(train_data, label, class_list) - feature_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcb255b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "The Resultant Decision Tree is:\n",
      "\n",
      "{'day': {1: 'no', 2: 'no', 3: 'yes', 4: 'yes', 5: 'yes', 6: 'no', 7: 'yes', 8: 'no', 9: 'yes', 10: 'yes', 11: 'yes', 12: 'yes', 13: 'yes', 14: 'no'}}\n"
     ]
    }
   ],
   "source": [
    "def id3(df, target_attribute_name, attribute_names, default_class = None):\n",
    "    from collections import Counter\n",
    "    count = Counter(x for x in df[target_attribute_name])\n",
    "    if len(count)==1:\n",
    "        return next(iter(count))\n",
    "    elif df.empty or (not attribute_names):\n",
    "        return default_class\n",
    "    else:\n",
    "        class_list = df[label].unique()\n",
    "        gain = [\n",
    "            calc_info_gain(df, attr, target_attribute_name,class_list) for attr in attribute_names\n",
    "        ]\n",
    "        print()\n",
    "        index_of_max = gain.index(max(gain))\n",
    "        best_attr = attribute_names[index_of_max]\n",
    "        \n",
    "        tree = {best_attr:{}}\n",
    "        \n",
    "        remaining_attribute_names = [ i for i in attribute_names if i!= best_attr ]\n",
    "        \n",
    "        for attr_val, data_subset in df.groupby(best_attr):\n",
    "                subtree = id3(data_subset, target_attribute_name, remaining_attribute_names, default_class)\n",
    "                tree[best_attr][attr_val] = subtree\n",
    "        \n",
    "        return tree\n",
    "\n",
    "tree = id3(df_tennis,'playtennis',attribute_names)\n",
    "print(\"\\n\\nThe Resultant Decision Tree is:\\n\")\n",
    "print(tree)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43b36c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tree, instance):\n",
    "    if not isinstance(tree, dict): \n",
    "        return tree \n",
    "    else:\n",
    "        root_node = next(iter(tree)) \n",
    "        feature_value = instance[root_node] \n",
    "        if feature_value in tree[root_node]: \n",
    "            return predict(tree[root_node][feature_value], instance) \n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e47d048f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day              t1\n",
      "outlook        rain\n",
      "temp           cool\n",
      "humidity     normal\n",
      "wind         strong\n",
      "Name: 0, dtype: object\n",
      "predicted value= None\n",
      "day             t2\n",
      "outlook      sunny\n",
      "temp          mild\n",
      "humidity    normal\n",
      "wind        strong\n",
      "Name: 1, dtype: object\n",
      "predicted value= None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def evaluate(tree, test_data_m, label):\n",
    "      for index, row in test_data_m.iterrows(): \n",
    "        result = predict(tree, test_data_m.iloc[index]) \n",
    "        print(row)\n",
    "        print(\"predicted value=\",result)\n",
    "\n",
    "test_data_m = pd.read_csv(\"id3_test.csv\") \n",
    "\n",
    "evaluate(tree, test_data_m, 'playtennis') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec2c98a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['day', 'outlook', 'temperature', 'humidity', 'wind']\n",
      "\n",
      "\n",
      "\n",
      "The Resultant Decision Tree is:\n",
      "\n",
      "{'day': {1: 'no', 2: 'no', 3: 'yes', 4: 'yes', 5: 'yes', 6: 'no', 7: 'yes', 8: 'no', 9: 'yes', 10: 'yes', 11: 'yes', 12: 'yes', 13: 'yes', 14: 'no'}}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "df_tennis = pd.read_csv('lab3_data.csv')\n",
    "\n",
    "attribute_names = list(df_tennis.columns)\n",
    "attribute_names.remove('playtennis')\n",
    "label=\"playtennis\"\n",
    "print(attribute_names)\n",
    "\n",
    "def calc_total_entropy(train_data, label, class_list):\n",
    "    total_row = train_data.shape[0] #the total size of the dataset\n",
    "    total_entr = 0\n",
    "    \n",
    "    for c in class_list: #for each class in the label\n",
    "        total_class_count = train_data[train_data[label] == c].shape[0] #number of the class\n",
    "        total_class_entr = - (total_class_count/total_row)*np.log2(total_class_count/total_row) #entropy of the class\n",
    "        total_entr += total_class_entr #adding the class entropy to the total entropy of the dataset\n",
    "    \n",
    "    return total_entr\n",
    "\n",
    "def calc_entropy(feature_value_data, label, class_list):\n",
    "    class_count = feature_value_data.shape[0]\n",
    "    entropy = 0\n",
    "    \n",
    "    for c in class_list:\n",
    "        label_class_count = feature_value_data[feature_value_data[label] == c].shape[0] #row count of class c \n",
    "        entropy_class = 0\n",
    "        if label_class_count != 0:\n",
    "            probability_class = label_class_count/class_count #probability of the class\n",
    "            entropy_class = - probability_class * np.log2(probability_class)  #entropy\n",
    "        entropy += entropy_class\n",
    "    return entropy\n",
    "\n",
    "def calc_info_gain(train_data,feature_name, label, class_list):\n",
    "    feature_value_list = train_data[feature_name].unique() #unqiue values of the feature\n",
    "    total_row = train_data.shape[0]\n",
    "    feature_info = 0.0\n",
    "    \n",
    "    for feature_value in feature_value_list:\n",
    "        feature_value_data = train_data[train_data[feature_name] == feature_value] #filtering rows with that feature_value\n",
    "        feature_value_count = feature_value_data.shape[0]\n",
    "        feature_value_entropy = calc_entropy(feature_value_data, label, class_list) #calculcating entropy for the feature value\n",
    "        feature_value_probability = feature_value_count/total_row\n",
    "        feature_info += feature_value_probability * feature_value_entropy #calculating information of the feature value\n",
    "        \n",
    "    return calc_total_entropy(train_data, label, class_list) - feature_info #calculating information gain by subtracting\n",
    "\n",
    "def id3(df, target_attribute_name, attribute_names, default_class = None):\n",
    "    from collections import Counter\n",
    "    count = Counter(x for x in df[target_attribute_name])\n",
    "    if len(count)==1:\n",
    "        return next(iter(count))\n",
    "    elif df.empty or (not attribute_names):\n",
    "        return default_class\n",
    "    else:\n",
    "        default_class = max(count.keys())\n",
    "        class_list = df[label].unique()\n",
    "        gain = [\n",
    "            calc_info_gain(df, attr, target_attribute_name,class_list) for attr in attribute_names\n",
    "        ]\n",
    "        print()\n",
    "        index_of_max = gain.index(max(gain))\n",
    "        best_attr = attribute_names[index_of_max]\n",
    "        \n",
    "        tree = {best_attr:{}}\n",
    "        \n",
    "        remaining_attribute_names = [ i for i in attribute_names if i!= best_attr ]\n",
    "        \n",
    "        for attr_val, data_subset in df.groupby(best_attr):\n",
    "                subtree = id3(data_subset, target_attribute_name, remaining_attribute_names, default_class)\n",
    "                tree[best_attr][attr_val] = subtree\n",
    "        \n",
    "        return tree\n",
    "\n",
    "tree = id3(df_tennis,'playtennis',attribute_names)\n",
    "print(\"\\n\\nThe Resultant Decision Tree is:\\n\")\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b93906b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
